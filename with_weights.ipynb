{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fbg4zIur1Wjw",
    "outputId": "31d31cfe-ec9e-491a-b4b9-007f032c41df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from itertools import product\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    weighted_keywords = weights[1] * keywords\n",
    "    weighted_custom_data_structures = weights[0] * custom_data_structures\n",
    "\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# CatBoost parameter options\n",
    "iterations_list = [1500, 1000, 2000]\n",
    "learning_rate_list = [0.01, 0.05]\n",
    "l2_leaf_reg_list = [5, 7]\n",
    "early_stopping_rounds_list = [15, 30]\n",
    "\n",
    "# Generate all combinations of CatBoost parameters\n",
    "param_combinations = list(product(iterations_list, learning_rate_list, l2_leaf_reg_list, early_stopping_rounds_list))\n",
    "\n",
    "# Load data\n",
    "file_path = \"pca.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1), (1,9),(9,1),(2,8),(8,2),(3,7),(7,3),(4,6),(6,4),(0.1,0.9),(0.9,0.1),(0.2,0.8),(0.8,0.2),(0.3,0.7),(0.7,0.3),(0.4,0.6),(0.6,0.4)]\n",
    "fusions = [\"add\", \"concatenate\"]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate models with different combinations\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        for params in param_combinations:\n",
    "            iterations, learning_rate, l2_leaf_reg, early_stopping_rounds = params\n",
    "\n",
    "            # Print parameters being tested\n",
    "            print(f\"Testing CatBoost with iterations={iterations}, learning_rate={learning_rate}, l2_leaf_reg={l2_leaf_reg}, early_stopping_rounds={early_stopping_rounds}\")\n",
    "\n",
    "            model = CatBoostRegressor(\n",
    "                iterations=iterations,\n",
    "                learning_rate=learning_rate,\n",
    "                l2_leaf_reg=l2_leaf_reg,\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                random_state=43,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Train metrics\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Test metrics\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Model\": \"CatBoost Regressor\",\n",
    "                \"Weights\": weights,\n",
    "                \"Fusion\": fusion,\n",
    "                \"Iterations\": iterations,\n",
    "                \"Learning Rate\": learning_rate,\n",
    "                \"L2 Leaf Reg\": l2_leaf_reg,\n",
    "                \"Early Stopping Rounds\": early_stopping_rounds,\n",
    "                \"Train MAE\": train_mae,\n",
    "                \"Train MSE\": train_mse,\n",
    "                \"Train RMSE\": train_rmse,\n",
    "                \"Train R2\": train_r2,\n",
    "                \"Train MAPE\": train_mape,\n",
    "                \"Test MAE\": test_mae,\n",
    "                \"Test MSE\": test_mse,\n",
    "                \"Test RMSE\": test_rmse,\n",
    "                \"Test R2\": test_r2,\n",
    "                \"Test MAPE\": test_mape\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by Fusion and Test R2 in descending order\n",
    "results_df.sort_values(by=[\"Fusion\", \"Test R2\"], ascending=[True, False], inplace=True)\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"catboostpca2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1500, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=1000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.01, l2_leaf_reg=7, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=3, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=5, early_stopping_rounds=30\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=15\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=20\n",
      "Testing CatBoost with iterations=2000, learning_rate=0.05, l2_leaf_reg=7, early_stopping_rounds=30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 79\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting CatBoost with iterations=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, l2_leaf_reg=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml2_leaf_reg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, early_stopping_rounds=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mearly_stopping_rounds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\n\u001b[0;32m     71\u001b[0m     iterations\u001b[38;5;241m=\u001b[39miterations,\n\u001b[0;32m     72\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 79\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Train metrics\u001b[39;00m\n\u001b[0;32m     82\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(model\u001b[38;5;241m.\u001b[39mpredict(X_train))\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:5827\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5825\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5828\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5829\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5830\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:2400\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2397\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2408\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:1780\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from itertools import product\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    weighted_keywords = weights[1] * keywords\n",
    "    weighted_custom_data_structures = weights[0] * custom_data_structures\n",
    "\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# CatBoost parameter options\n",
    "iterations_list = [1500, 1000, 2000]\n",
    "learning_rate_list = [0.01, 0.05]\n",
    "l2_leaf_reg_list = [3, 5, 7]\n",
    "early_stopping_rounds_list = [15, 20, 30]\n",
    "\n",
    "# Generate all combinations of CatBoost parameters\n",
    "param_combinations = list(product(iterations_list, learning_rate_list, l2_leaf_reg_list, early_stopping_rounds_list))\n",
    "\n",
    "# Load data\n",
    "file_path = \"IG.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1), (0.4, 0.6), (0.1, 0.9)]\n",
    "fusions = [\"add\", \"concatenate\"]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate models with different combinations\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        for params in param_combinations:\n",
    "            iterations, learning_rate, l2_leaf_reg, early_stopping_rounds = params\n",
    "\n",
    "            # Print parameters being tested\n",
    "            print(f\"Testing CatBoost with iterations={iterations}, learning_rate={learning_rate}, l2_leaf_reg={l2_leaf_reg}, early_stopping_rounds={early_stopping_rounds}\")\n",
    "\n",
    "            model = CatBoostRegressor(\n",
    "                iterations=iterations,\n",
    "                learning_rate=learning_rate,\n",
    "                l2_leaf_reg=l2_leaf_reg,\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                random_state=43,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Train metrics\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Test metrics\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Model\": \"CatBoost Regressor\",\n",
    "                \"Weights\": weights,\n",
    "                \"Fusion\": fusion,\n",
    "                \"Iterations\": iterations,\n",
    "                \"Learning Rate\": learning_rate,\n",
    "                \"L2 Leaf Reg\": l2_leaf_reg,\n",
    "                \"Early Stopping Rounds\": early_stopping_rounds,\n",
    "                \"Train MAE\": train_mae,\n",
    "                \"Train MSE\": train_mse,\n",
    "                \"Train RMSE\": train_rmse,\n",
    "                \"Train R2\": train_r2,\n",
    "                \"Train MAPE\": train_mape,\n",
    "                \"Test MAE\": test_mae,\n",
    "                \"Test MSE\": test_mse,\n",
    "                \"Test RMSE\": test_rmse,\n",
    "                \"Test R2\": test_r2,\n",
    "                \"Test MAPE\": test_mape\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by Fusion and Test R2 in descending order\n",
    "results_df.sort_values(by=[\"Fusion\", \"Test R2\"], ascending=[True, False], inplace=True)\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"catboostactualIG.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuwkXGdwYOmO"
   },
   "source": [
    "For PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka8JzrmIwd9T",
    "outputId": "299c283b-dec9-411d-9cbe-88999e30e523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to pca_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    weighted_keywords = weights[1] * keywords\n",
    "    weighted_custom_data_structures = weights[0] * custom_data_structures\n",
    "\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15, 'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1, 'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3, 'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0, 'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Stacking regressor\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3, verbose=0),\n",
    ")\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data\n",
    "file_path = \"/content/pca.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1), (0.6, 0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1), (0.4, 0.6), (0.3, 0.7), (0.2, 0.8), (0.1, 0.9), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
    "fusions = [\"add\", \"concatenate\"]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate models\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Train metrics\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Test metrics\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Weights\": weights,\n",
    "                \"Fusion\": fusion,\n",
    "                \"Train MAE\": train_mae,\n",
    "                \"Train MSE\": train_mse,\n",
    "                \"Train RMSE\": train_rmse,\n",
    "                \"Train R2\": train_r2,\n",
    "                \"Train MAPE\": train_mape,\n",
    "                \"Test MAE\": test_mae,\n",
    "                \"Test MSE\": test_mse,\n",
    "                \"Test RMSE\": test_rmse,\n",
    "                \"Test R2\": test_r2,\n",
    "                \"Test MAPE\": test_mape\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by fusion method and Test R2 in descending order\n",
    "results_df.sort_values(by=[\"Fusion\", \"Test R2\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"pca_results.xlsx\", index=False)\n",
    "print(\"Results saved to pca_results.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE5hkUHRO0sZ"
   },
   "source": [
    "For CHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0XqXSDvtxey",
    "outputId": "3cf27269-569a-4a75-db12-68fe061b8e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to chi_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    weighted_keywords = weights[1] * keywords\n",
    "    weighted_custom_data_structures = weights[0] * custom_data_structures\n",
    "\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15, 'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1, 'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3, 'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0, 'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Stacking regressor\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3, verbose=0),\n",
    ")\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data\n",
    "file_path = \"/content/chi.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1), (0.6, 0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1), (0.4, 0.6), (0.3, 0.7), (0.2, 0.8), (0.1, 0.9), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
    "fusions = [\"add\", \"concatenate\"]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate models\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Train metrics\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Test metrics\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Weights\": weights,\n",
    "                \"Fusion\": fusion,\n",
    "                \"Train MAE\": train_mae,\n",
    "                \"Train MSE\": train_mse,\n",
    "                \"Train RMSE\": train_rmse,\n",
    "                \"Train R2\": train_r2,\n",
    "                \"Train MAPE\": train_mape,\n",
    "                \"Test MAE\": test_mae,\n",
    "                \"Test MSE\": test_mse,\n",
    "                \"Test RMSE\": test_rmse,\n",
    "                \"Test R2\": test_r2,\n",
    "                \"Test MAPE\": test_mape\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by fusion method and Test R2 in descending order\n",
    "results_df.sort_values(by=[\"Fusion\", \"Test R2\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"chi_results.xlsx\", index=False)\n",
    "print(\"Results saved to chi_results.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLB9zAV9YTmt"
   },
   "source": [
    "For Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqENy9u1YaKB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    weighted_keywords = weights[1] * keywords\n",
    "    weighted_custom_data_structures = weights[0] * custom_data_structures\n",
    "\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15, 'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1, 'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3, 'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0, 'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Stacking regressor\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3, verbose=0),\n",
    ")\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data\n",
    "file_path = \"/content/IG.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1), (0.6, 0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1), (0.4, 0.6), (0.3, 0.7), (0.2, 0.8), (0.1, 0.9), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
    "fusions = [\"add\", \"concatenate\"]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate models\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Train metrics\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Test metrics\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Weights\": weights,\n",
    "                \"Fusion\": fusion,\n",
    "                \"Train MAE\": train_mae,\n",
    "                \"Train MSE\": train_mse,\n",
    "                \"Train RMSE\": train_rmse,\n",
    "                \"Train R2\": train_r2,\n",
    "                \"Train MAPE\": train_mape,\n",
    "                \"Test MAE\": test_mae,\n",
    "                \"Test MSE\": test_mse,\n",
    "                \"Test RMSE\": test_rmse,\n",
    "                \"Test R2\": test_r2,\n",
    "                \"Test MAPE\": test_mape\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by fusion method and Test R2 in descending order\n",
    "results_df.sort_values(by=[\"Fusion\", \"Test R2\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"IG_results.xlsx\", index=False)\n",
    "print(\"Results saved to IG_results.xlsx.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
