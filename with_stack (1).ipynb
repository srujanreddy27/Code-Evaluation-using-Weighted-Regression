{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuwkXGdwYOmO"
   },
   "source": [
    "For PCA reduction(partial parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka8JzrmIwd9T",
    "outputId": "7ee2e37e-ef4c-4598-8618-5a55bf11f49b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusion method: add\n",
      "\n",
      "Model: CatBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.5431472081218274, MSE: 0.7766497461928934, RMSE: 0.8812773378414388, R2: 0.8679843037055672, MAPE: 9144364725625.494\n",
      "Test Metrics:\n",
      "MAE: 1.3238866396761133, MSE: 3.064777327935223, RMSE: 1.7506505442078446, R2: 0.4755706264128928, MAPE: 0.3558399203136045\n",
      "\n",
      "Model: XGBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.9604060913705583, MSE: 1.6385786802030458, RMSE: 1.280069795051444, R2: 0.7214727401733398, MAPE: 18288729451250.977\n",
      "Test Metrics:\n",
      "MAE: 1.4696356275303644, MSE: 3.445344129554656, RMSE: 1.8561638207751643, R2: 0.41044992208480835, MAPE: 0.40919606709080397\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Train Metrics:\n",
      "MAE: 1.3147208121827412, MSE: 2.912690355329949, RMSE: 1.7066605858605715, R2: 0.5048979965114674, MAPE: 22860911814063.777\n",
      "Test Metrics:\n",
      "MAE: 1.6842105263157894, MSE: 4.477732793522267, RMSE: 2.116065403885775, R2: 0.23379275140377742, MAPE: 0.4909163935479725\n",
      "\n",
      "Model: Bagging Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7299492385786802, MSE: 1.0954314720812184, RMSE: 1.0466286218526695, R2: 0.8137974688866759, MAPE: 18288729451250.938\n",
      "Test Metrics:\n",
      "MAE: 1.4291497975708503, MSE: 3.42914979757085, RMSE: 1.8517963704389448, R2: 0.41322103113833586, MAPE: 0.4164786967418546\n",
      "\n",
      "Model: Stacking Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7461928934010152, MSE: 1.2192893401015228, RMSE: 1.1042143542363152, R2: 0.7927439852946226, MAPE: 18288729451250.914\n",
      "Test Metrics:\n",
      "MAE: 1.3927125506072875, MSE: 3.279352226720648, RMSE: 1.810898182317451, R2: 0.43885364252898706, MAPE: 0.3704244585823533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    # Apply weights\n",
    "    weighted_keywords = weights[0] * keywords\n",
    "    weighted_custom_data_structures = weights[1] * custom_data_structures\n",
    "\n",
    "    # Apply fusion\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15,'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3,'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0,'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Create a stacking regressor using the models as base learners\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3,verbose=0),\n",
    ")\n",
    "\n",
    "# Add the stacking model to the models dictionary\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data without reduction\n",
    "file_path = \"/content/pca.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1)]\n",
    "fusions = [\"add\"]\n",
    "\n",
    "# Print results directly\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        print(f\"\\nFusion method: {fusion}\")\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics for training set\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Predict and calculate metrics for testing set\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\nModel: {name}\")\n",
    "            print(\"Train Metrics:\")\n",
    "            print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R2: {train_r2}, MAPE: {train_mape}\")\n",
    "            print(\"Test Metrics:\")\n",
    "            print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R2: {test_r2}, MAPE: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FczC8GkZ1-kr",
    "outputId": "f509bd02-5858-4120-c4d3-b234a0f91616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusion method: concatenate\n",
      "\n",
      "Model: CatBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.584771573604061, MSE: 0.8243654822335026, RMSE: 0.9079457485078625, R2: 0.8598735354364976, MAPE: 9144364725625.5\n",
      "Test Metrics:\n",
      "MAE: 1.291497975708502, MSE: 2.7732793522267207, RMSE: 1.6653165921910227, R2: 0.5254503026325384, MAPE: 0.336053274211169\n",
      "\n",
      "Model: XGBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.9187817258883249, MSE: 1.5401015228426396, RMSE: 1.241008268643944, R2: 0.738211989402771, MAPE: 18288729451250.97\n",
      "Test Metrics:\n",
      "MAE: 1.408906882591093, MSE: 3.2550607287449393, RMSE: 1.8041786853704207, R2: 0.44301027059555054, MAPE: 0.37971370734528626\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Train Metrics:\n",
      "MAE: 1.2873096446700507, MSE: 2.7593908629441626, RMSE: 1.66114143375697, R2: 0.5309559966950743, MAPE: 22860911814063.758\n",
      "Test Metrics:\n",
      "MAE: 1.5870445344129556, MSE: 4.089068825910931, RMSE: 2.0221446105338092, R2: 0.3002989863633049, MAPE: 0.4370525673157253\n",
      "\n",
      "Model: Bagging Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.6974619289340102, MSE: 1.0365482233502539, RMSE: 1.018110123390517, R2: 0.8238065020697832, MAPE: 18288729451250.926\n",
      "Test Metrics:\n",
      "MAE: 1.3360323886639676, MSE: 3.165991902834008, RMSE: 1.779323439634854, R2: 0.4582512943921826, MAPE: 0.36797602981813504\n",
      "\n",
      "Model: Stacking Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7360406091370558, MSE: 1.2538071065989849, RMSE: 1.119735284162728, R2: 0.7868766210148701, MAPE: 18288729451250.902\n",
      "Test Metrics:\n",
      "MAE: 1.3279352226720649, MSE: 2.9473684210526314, RMSE: 1.7167901505579042, R2: 0.49566105155691675, MAPE: 0.33278388278388277\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    # Apply weights\n",
    "    weighted_keywords = weights[0] * keywords\n",
    "    weighted_custom_data_structures = weights[1] * custom_data_structures\n",
    "\n",
    "    # Apply fusion\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15,'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3,'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0,'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Create a stacking regressor using the models as base learners\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3,verbose=0),\n",
    ")\n",
    "\n",
    "# Add the stacking model to the models dictionary\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data without reduction\n",
    "file_path = \"/content/pca.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1)]\n",
    "fusions = [\"concatenate\"]\n",
    "\n",
    "# Print results directly\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        print(f\"\\nFusion method: {fusion}\")\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics for training set\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Predict and calculate metrics for testing set\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\nModel: {name}\")\n",
    "            print(\"Train Metrics:\")\n",
    "            print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R2: {train_r2}, MAPE: {train_mape}\")\n",
    "            print(\"Test Metrics:\")\n",
    "            print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R2: {test_r2}, MAPE: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLB9zAV9YTmt"
   },
   "source": [
    "For Information Gain(No parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqENy9u1YaKB",
    "outputId": "039a7516-6515-4939-82cd-691cabe4a686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusion method: add\n",
      "\n",
      "Model: CatBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.5299492385786801, MSE: 0.7573604060913706, RMSE: 0.8702645609763565, R2: 0.8712631249207231, MAPE: 9144364725625.486\n",
      "Test Metrics:\n",
      "MAE: 1.3562753036437247, MSE: 3.2753036437246963, RMSE: 1.8097799987083227, R2: 0.43954641580981546, MAPE: 0.38681961313540264\n",
      "\n",
      "Model: XGBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.9898477157360406, MSE: 1.700507614213198, RMSE: 1.3040351276760906, R2: 0.7109460234642029, MAPE: 18288729451250.992\n",
      "Test Metrics:\n",
      "MAE: 1.4736842105263157, MSE: 3.611336032388664, RMSE: 1.900351554946785, R2: 0.3820462226867676, MAPE: 0.4324481074481074\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Train Metrics:\n",
      "MAE: 1.3766497461928935, MSE: 3.0639593908629443, RMSE: 1.750416919154675, R2: 0.47918513540314, MAPE: 27433094176876.496\n",
      "Test Metrics:\n",
      "MAE: 1.6518218623481782, MSE: 4.42914979757085, RMSE: 2.104554536611216, R2: 0.24210603077371828, MAPE: 0.507211940106677\n",
      "\n",
      "Model: Bagging Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7401015228426396, MSE: 1.1197969543147208, RMSE: 1.0582045900083408, R2: 0.8096557999833212, MAPE: 18288729451250.94\n",
      "Test Metrics:\n",
      "MAE: 1.437246963562753, MSE: 3.5668016194331984, RMSE: 1.8885977918638999, R2: 0.38966673959016984, MAPE: 0.43881819934451516\n",
      "\n",
      "Model: Stacking Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7766497461928934, MSE: 1.4142131979695431, RMSE: 1.189206961789891, R2: 0.7596106340677846, MAPE: 18288729451250.934\n",
      "Test Metrics:\n",
      "MAE: 1.408906882591093, MSE: 3.3846153846153846, RMSE: 1.8397324220155997, R2: 0.4208415372274483, MAPE: 0.40004498425551055\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    # Apply weights\n",
    "    weighted_keywords = weights[0] * keywords\n",
    "    weighted_custom_data_structures = weights[1] * custom_data_structures\n",
    "\n",
    "    # Apply fusion\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15,'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3,'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0,'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Create a stacking regressor using the models as base learners\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3,verbose=0),\n",
    ")\n",
    "\n",
    "# Add the stacking model to the models dictionary\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data without reduction\n",
    "file_path = \"/content/IG.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1)]\n",
    "fusions = [\"add\"]\n",
    "\n",
    "# Print results directly\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        print(f\"\\nFusion method: {fusion}\")\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics for training set\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Predict and calculate metrics for testing set\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\nModel: {name}\")\n",
    "            print(\"Train Metrics:\")\n",
    "            print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R2: {train_r2}, MAPE: {train_mape}\")\n",
    "            print(\"Test Metrics:\")\n",
    "            print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R2: {test_r2}, MAPE: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Z9cDS423phs",
    "outputId": "a4798779-407c-4e23-d559-05d4cd7d3dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusion method: concatenate\n",
      "\n",
      "Model: CatBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.5218274111675127, MSE: 0.7553299492385787, RMSE: 0.8690972035615916, R2: 0.8716082639960027, MAPE: 4572182362812.806\n",
      "Test Metrics:\n",
      "MAE: 1.311740890688259, MSE: 3.02834008097166, RMSE: 1.7402126539511371, R2: 0.4818055859403485, MAPE: 0.3326216181479339\n",
      "\n",
      "Model: XGBoost Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.9218274111675127, MSE: 1.5289340101522844, RMSE: 1.236500711747585, R2: 0.7401102781295776, MAPE: 18288729451250.977\n",
      "Test Metrics:\n",
      "MAE: 1.417004048582996, MSE: 3.3927125506072873, RMSE: 1.84193174428568, R2: 0.41945594549179077, MAPE: 0.3954646230962021\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Train Metrics:\n",
      "MAE: 1.3380710659898478, MSE: 2.984771573604061, RMSE: 1.727649146558427, R2: 0.49264555933904286, MAPE: 22860911814063.78\n",
      "Test Metrics:\n",
      "MAE: 1.6153846153846154, MSE: 4.295546558704453, RMSE: 2.0725700371047666, R2: 0.2649675490410559, MAPE: 0.4649733307628044\n",
      "\n",
      "Model: Bagging Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7065989847715736, MSE: 1.068020304568528, RMSE: 1.0334506783434456, R2: 0.81845684640295, MAPE: 13716547088438.246\n",
      "Test Metrics:\n",
      "MAE: 1.4129554655870444, MSE: 3.4129554655870447, RMSE: 1.847418595117805, R2: 0.41599212426164955, MAPE: 0.40661911188226973\n",
      "\n",
      "Model: Stacking Regressor\n",
      "Train Metrics:\n",
      "MAE: 0.7411167512690355, MSE: 1.2609137055837563, RMSE: 1.122904139089244, R2: 0.7856686342513917, MAPE: 18288729451250.934\n",
      "Test Metrics:\n",
      "MAE: 1.3643724696356276, MSE: 3.2024291497975708, RMSE: 1.789533221205343, R2: 0.4520163348647269, MAPE: 0.36890784653942554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    keywords = df[[f'Keywords_Vector_{i}' for i in range(20)]]\n",
    "    custom_data_structures = df[[f'Custom_Data_Structures_Vector_{i}' for i in range(20)]]\n",
    "    final_marks = df[\"Final_Marks\"]\n",
    "    return keywords, custom_data_structures, final_marks\n",
    "\n",
    "# Function to pad vectors with zeros to match length\n",
    "def pad_with_zeros(vector, max_length):\n",
    "    vector = np.atleast_2d(vector)\n",
    "    if vector.shape[1] < max_length:\n",
    "        padding = np.zeros((vector.shape[0], max_length - vector.shape[1]))\n",
    "        vector = np.hstack((vector, padding))\n",
    "    return vector\n",
    "\n",
    "# Reduction and combination strategies\n",
    "def combine_vectors(keywords, custom_data_structures, weights, fusion):\n",
    "    # Apply weights\n",
    "    weighted_keywords = weights[0] * keywords\n",
    "    weighted_custom_data_structures = weights[1] * custom_data_structures\n",
    "\n",
    "    # Apply fusion\n",
    "    if fusion == \"add\":\n",
    "        max_length = max(weighted_keywords.shape[1], weighted_custom_data_structures.shape[1])\n",
    "        weighted_keywords = pad_with_zeros(weighted_keywords, max_length)\n",
    "        weighted_custom_data_structures = pad_with_zeros(weighted_custom_data_structures, max_length)\n",
    "        combined_vectors = weighted_keywords + weighted_custom_data_structures\n",
    "    elif fusion == \"concatenate\":\n",
    "        combined_vectors = np.hstack((weighted_keywords, weighted_custom_data_structures))\n",
    "    return combined_vectors\n",
    "\n",
    "# Model definitions\n",
    "catboost_params = {\n",
    "    'verbose': 0,\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'early_stopping_rounds': 15,'random_state': 43\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,'random_state': 43\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 3,'random_state': 43\n",
    "}\n",
    "\n",
    "bagging_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 0.8,\n",
    "    'max_features': 1.0,'random_state': 43\n",
    "}\n",
    "\n",
    "# Base models\n",
    "models = {\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(**catboost_params),\n",
    "    \"XGBoost Regressor\": XGBRegressor(**xgboost_params),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**random_forest_params),\n",
    "    \"Bagging Regressor\": BaggingRegressor(**bagging_params)\n",
    "}\n",
    "\n",
    "# Create a stacking regressor using the models as base learners\n",
    "estimators = [(name, model) for name, model in models.items()]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=3,verbose=0),\n",
    ")\n",
    "\n",
    "# Add the stacking model to the models dictionary\n",
    "models[\"Stacking Regressor\"] = stacking_model\n",
    "\n",
    "# Load data without reduction\n",
    "file_path = \"/content/IG.xlsx\"\n",
    "keywords, custom_data_structures, final_marks = load_data(file_path)\n",
    "\n",
    "# Weights and fusion types\n",
    "weights_options = [(1, 1)]\n",
    "fusions = [\"concatenate\"]\n",
    "\n",
    "# Print results directly\n",
    "for weights in weights_options:\n",
    "    for fusion in fusions:\n",
    "        combined_vectors = combine_vectors(keywords, custom_data_structures, weights, fusion)\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combined_vectors, final_marks, test_size=0.2, random_state=42, stratify=final_marks)\n",
    "\n",
    "        print(f\"\\nFusion method: {fusion}\")\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics for training set\n",
    "            y_train_pred = np.round(model.predict(X_train))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "            train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "            # Predict and calculate metrics for testing set\n",
    "            y_test_pred = np.round(model.predict(X_test))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "            test_rmse = np.sqrt(test_mse)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\nModel: {name}\")\n",
    "            print(\"Train Metrics:\")\n",
    "            print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R2: {train_r2}, MAPE: {train_mape}\")\n",
    "            print(\"Test Metrics:\")\n",
    "            print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R2: {test_r2}, MAPE: {test_mape}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
